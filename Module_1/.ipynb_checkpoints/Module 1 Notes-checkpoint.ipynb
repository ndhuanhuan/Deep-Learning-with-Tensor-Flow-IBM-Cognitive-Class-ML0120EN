{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To define variables we use the command tf.variable(). To be able to use variables in a computation graph it is necessary to initialize them before running the graph in a session. This is done by running tf.global_variables_initializer().\n",
    "\n",
    "Variables must be initialized by running an initialization operation after having launched the graph.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we create a placeholder:\n",
    "\n",
    "a=tf.placeholder(tf.float32)\n",
    "And define a simple multiplication operation:\n",
    "\n",
    "b=a*2\n",
    "\n",
    "Now we need to define and run the session, but since we created a \"hole\" in the model to pass the data, when we initialize the session we are obligated to pass an argument with the data, otherwise we would get an error.\n",
    "To pass the data to the model we call the session with an extra argument feed_dict in which we should pass a dictionary with each placeholder name folowed by its respective data, just like this:\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    result = sess.run(b,feed_dict={a:3.5})\n",
    "    print result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "dictionary={a: [ [ [1,2,3],[4,5,6],[7,8,9],[10,11,12] ] , [ [13,14,15],[16,17,18],[19,20,21],[22,23,24] ] ] }\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    result = sess.run(b,feed_dict=dictionary)\n",
    "    print result\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we initialize the variables a and b, with any random guess, and then we define the linear function:\n",
    "\n",
    "a = tf.Variable(1.0)\n",
    "b = tf.Variable(0.2)\n",
    "y = a * x_data + b\n",
    "In a linear regression, we minimize the squared error of the equation that we want to adjust minus the target values (the data that we have), so we define the equation to be minimized as loss.\n",
    "To find Loss's value, we use tf.reduce_mean(). This function finds the mean of a multidimensional tensor, and the result can have a diferent dimension.\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(y - y_data))\n",
    "loss = tf.reduce_mean(tf.square(y - y_data))\n",
    "Then, we define the optimizer method. Here we will use a simple gradient descent with a learning rate of 0.5: \n",
    "\n",
    "Now we will define the training method of our graph, what method we will use for minimize the loss? We will use the tf.train.GradientDescentOptimizer.\n",
    ".minimize()__ will minimize the error function of our optimizer, resulting in a better model.\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "train = optimizer.minimize(loss)\n",
    "Don't forget to initialize the variables before executing a graph:\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
